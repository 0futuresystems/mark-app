Project: Lot Logger — “Generate Description” with GPT-4o-mini (vision)

Goal (plain English):
Add a one-click “Generate” button next to the Description field on the Lot detail page so Mark (tech-averse, 65 years old user of this app) can take/upload photos and then auto-fill a solid auction title + bullet description + keywords from those photos using OpenAI GPT-4o-mini (vision). Keep it cheap, fast, and dead simple to use.

What to build:

UI affordance

On the lot screen (where Photos and Description are), add a small secondary button labeled “Generate from Photos” beside the Description header.

While it’s generating, show a spinner and “Analyzing photos…”; disable the button.

After success, auto-populate:

Title field (if present)

Description field (bulleted list)

Keywords/tags field (if present)

Always show a subtle disclaimer line: “Attribution/age are best estimates.”

Server endpoint (secure)

Create a server-side endpoint that the UI calls, e.g. POST /api/generate-description.

It should:

Receive lotId.

Fetch that lot’s images (use the best main image + 1 close-up if available).

(Optional, but try) Extract visible marks via OCR (e.g., Tesseract.js or a light server lib) and include in the prompt.

Resize images before sending to the model (longest side max 1024 px) to control cost.

Call OpenAI GPT-4o-mini (vision) with a structured prompt (below) and return a strict JSON payload.

Keep the OpenAI key server-side only.

Model & prompt

Model: gpt-4o-mini with image input.

System prompt (use as the model’s role/instructions):
“You are an expert auction cataloger for antiques & vintage items. Be conservative: if unsure, say ‘unknown’. Never invent maker names or dates. Keep language clear, neutral, and buyer-friendly.”

User content (template): include 1–2 images + the following text:

Produce a JSON object with keys:
- title: <= 70 characters, no emojis.
- description_bullets: 4–6 concise bullets covering: maker (if known), material, style/era (best estimate), condition notes, notable defects, and estimated size if visible (“approx.”).
- keywords: 8–12 SEO keywords, comma-separated.
- caution: always "Attribution/age are cataloger’s best estimate."

Visible marks/logos from OCR (may be empty): {{ocr_text}}
Context: General antiques/vintage household/collectibles for an online auction.
Output strictly as JSON. Do not include any prose outside the JSON.


Cap output to ~220–300 tokens.

Cost & performance controls

Resize images to 1024 px max edge; send max 2 images (primary + marks close-up).

Enforce a server-side timeout (e.g., 15s) and retry once on 429/5xx.

If the call fails, show a friendly toast: “Couldn’t generate. Try again or edit manually.”

Data write-back

After receiving JSON, map fields to our lot:

title → Lot title (create the field if we don’t have one yet).

description_bullets → Join with • bullets into the Description textarea.

keywords → Tags/keywords field if available; otherwise append at the end of description under “Keywords:”.

caution → Append as a final line in italic/small text in the UI only (don’t save if we already store a global disclaimer).

Save to IndexedDB/Supabase/wherever the lot currently persists.

Config & secrets

Add OPENAI_API_KEY in the project’s environment/secrets.

Add a feature flag like NEXT_PUBLIC_ENABLE_AI_DESC=true so I can toggle the button.

Accessibility & UX

Keyboard focus and ARIA labels for the Generate button.

Don’t change the existing theme; match current button styles (use a subtle variant).

Provide an “Undo” link after auto-fill to restore the previous description.

Edge cases

No photos found → disable button with tooltip “Add a photo to generate.”

Blurry/ambiguous images → still return a safe output with “unknown” where needed.

Extremely long outputs → truncate gracefully and keep within our token cap.

Testing checklist

One clear photo of a teapot → sensible title, 5 bullets, keywords, disclaimer.

Two photos (front + maker’s mark) → maker picked up when visible via OCR.

No internet / API error → proper error toast; no data overwritten.

Token/cost sanity: confirm images are resized and only 1–2 get sent.

Documentation (short)

Add a brief README section: how the feature works, where to set the API key, how to enable/disable, and cost notes (~$1 per 500 lots at our settings).

Success criteria:

Mark can tap “Generate from Photos” and get a usable, conservative description in under ~8 seconds, most of the time, with <$0.003 per lot at our default settings.

No hallucinated makers/dates; “unknown” appears when unsure.

Works offline-first UI wise (button disabled) and gracefully syncs when online.